{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e54006c5",
   "metadata": {},
   "source": [
    "# Resume Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633afe8e",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "All these commands run in terminal (Ubuntu 20.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6defcff",
   "metadata": {},
   "source": [
    "Upgrading pip "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0d6dbca",
   "metadata": {},
   "source": [
    "sudo pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df724fe2",
   "metadata": {},
   "source": [
    "### 1.1 PaddleOCR\n",
    "\n",
    "* **<font color=red>Installing PaddlePaddle</font>**\n",
    "\n",
    "Before executing next cell please check this link\n",
    "\n",
    "https://www.paddlepaddle.org.cn/en/install/quick?docurl=/documentation/docs/en/install/pip/linux-pip_en.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f79dfb",
   "metadata": {},
   "source": [
    "Installing PaddlePaddle"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb41045c",
   "metadata": {},
   "source": [
    "sudo python3 -m pip install paddlepaddle==2.3.2 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cb60f5",
   "metadata": {},
   "source": [
    "* **<font color=red>Installing PaddleOCR</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d802ce",
   "metadata": {},
   "source": [
    "Installing Git"
   ]
  },
  {
   "cell_type": "raw",
   "id": "438fb927",
   "metadata": {},
   "source": [
    "sudo apt install git-all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ef1252",
   "metadata": {},
   "source": [
    "Clone PaddleOCR repo"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa4cd9ad",
   "metadata": {},
   "source": [
    "git clone https://github.com/PaddlePaddle/PaddleOCR.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b6331",
   "metadata": {},
   "source": [
    "Get into PaddleOCR folder"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d10d1ef",
   "metadata": {},
   "source": [
    "cd PaddleOCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d917b9",
   "metadata": {},
   "source": [
    "Installing PaddleOCR's requirements"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58733db6",
   "metadata": {},
   "source": [
    "sudo pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061c9815",
   "metadata": {},
   "source": [
    "In case you face any problem in protobuf version"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2fe8c8f1",
   "metadata": {},
   "source": [
    "sudo pip install protobuf==3.20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f0e65",
   "metadata": {},
   "source": [
    "Installing PaddleOCR"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20d59433",
   "metadata": {},
   "source": [
    "sudo python3 setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0c1aec",
   "metadata": {},
   "source": [
    "### 1.2 LayoutParser\n",
    "\n",
    "* **<font color=red>Installing the LayoutParser main library</font>**\n",
    "\n",
    "Before executing next cell please check this link\n",
    "\n",
    "https://layout-parser.github.io/tutorials/installation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b769e19",
   "metadata": {},
   "source": [
    "sudo pip install layoutparser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a9ba8",
   "metadata": {},
   "source": [
    "* **<font color=red>Installing Detectron2 for Using Layout Models</font>**\n",
    "\n",
    "Before executing next cell please check this link\n",
    "\n",
    "https://github.com/facebookresearch/detectron2/blob/main/INSTALL.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59679764",
   "metadata": {},
   "source": [
    "Installing Detectron2's requirements"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33afb6ac",
   "metadata": {},
   "source": [
    "sudo pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "sudo apt-get install python3-opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30187e5a",
   "metadata": {},
   "source": [
    "Build Detectron2 from Source"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8da2dba",
   "metadata": {},
   "source": [
    "sudo pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f3c67a",
   "metadata": {},
   "source": [
    "* **<font color=red>Installing Tesseract</font>**\n",
    "\n",
    "Before executing next cell please check this link\n",
    "\n",
    "https://tesseract-ocr.github.io/tessdoc/Installation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66159d35",
   "metadata": {},
   "source": [
    "Installing OCR utils"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1fad39f1",
   "metadata": {},
   "source": [
    "sudo pip install layoutparser[ocr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe346b3",
   "metadata": {},
   "source": [
    "Installing Tesseract"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d970b17c",
   "metadata": {},
   "source": [
    "sudo apt install tesseract-ocr\n",
    "sudo apt install libtesseract-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c52f2f",
   "metadata": {},
   "source": [
    "### If you get this error : No module named 'tools.infer' \n",
    "\n",
    "check this for debugging : https://github.com/PaddlePaddle/PaddleOCR/issues/1024#issuecomment-1105946934\n",
    "\n",
    "You will find that you need to open this 2 files and change \"tools\" by \"paddleocr.tools\" :\n",
    "\n",
    "/usr/local/lib/python3.8/dist-packages/paddleocr/paddleocr.py\n",
    "\n",
    "/usr/local/lib/python3.8/dist-packages/paddleocr/tools/infer/predict_system.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46001615",
   "metadata": {},
   "source": [
    "### 1.3 Googletrans"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3014baa7",
   "metadata": {},
   "source": [
    "sudo pip install googletrans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d1dde3",
   "metadata": {},
   "source": [
    "### 1.4 SpaCy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f1d3a28",
   "metadata": {},
   "source": [
    "sudo pip install -U pip setuptools wheel\n",
    "sudo pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee4c3ee",
   "metadata": {},
   "source": [
    "### 1.5 SkillNer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b2d37b1",
   "metadata": {},
   "source": [
    "sudo pip install skillNer\n",
    "sudo python3 -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc54f9",
   "metadata": {},
   "source": [
    "### 1.6 Stanza"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dab5e945",
   "metadata": {},
   "source": [
    "sudo pip install stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dacf76",
   "metadata": {},
   "source": [
    "## 2. Resume Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ea6ef7",
   "metadata": {},
   "source": [
    "### 2.1 Resume Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cef7957",
   "metadata": {},
   "source": [
    "Converting the resume from pdf to image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c78f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = './cv7.pdf'\n",
    "img_name = pdf_path[2:-4] + '.jpg'\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    " \n",
    "images = convert_from_path(pdf_path)\n",
    "\n",
    "for i in range(len(images)) : images[i].save(img_name, 'JPEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf1d19a",
   "metadata": {},
   "source": [
    "Load the resume image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d72899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(img_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b4c57",
   "metadata": {},
   "source": [
    "Dispaly the resume image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63bfeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772ecffb",
   "metadata": {},
   "source": [
    "### 2.2 Resume Text Extraction\n",
    "\n",
    "#### 2.2.1 Layout Analysis\n",
    "\n",
    "* **<font color=red>PaddleOCR</font>**\n",
    "\n",
    "In this section we will use PaddleOCR as a text detector due to its high detection accuracy compared to LayoutParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ea8fc",
   "metadata": {},
   "source": [
    "Detecting boxes texts by position from resume using PaddleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd835764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR,draw_ocr\n",
    "\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en', show_log = False)\n",
    "\n",
    "paddleOCR_result = ocr.ocr(img_name, cls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c2aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in paddleOCR_result : print(x, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10ce323",
   "metadata": {},
   "source": [
    "Displaying paddleOCR's result in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf42de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "boxes  = [line[0] for line in paddleOCR_result]\n",
    "txts   = [line[1][0] for line in paddleOCR_result]\n",
    "scores = [line[1][1] for line in paddleOCR_result]\n",
    "\n",
    "im_show = draw_ocr(image, boxes, txts, scores, font_path='/home/yns/PaddleOCR/doc/fonts/simfang.ttf')\n",
    "im_show = Image.fromarray(im_show)\n",
    "#im_show.save('paddleOCR_result.jpg')\n",
    "im_show.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0bffb7",
   "metadata": {},
   "source": [
    "* **<font color=red>LayoutParser</font>**\n",
    "\n",
    "Next, we will use LayoutParser for resume segmentation to find the most probable layout boxes that divide resume meaningfully using two pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae95c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import layoutparser as lp\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade741ab",
   "metadata": {},
   "source": [
    "Converting image to array list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277bb075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = np.asarray(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591a8340",
   "metadata": {},
   "source": [
    "Detecting layouts by position from resume using First model (Mask R-CNN pre-trained on PubLayNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ab632",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = lp.Detectron2LayoutModel('lp://PubLayNet/mask_rcnn_X_101_32x8d_FPN_3x/config',\n",
    "                                 extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.5],\n",
    "                                 label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3:\"Table\", 4:\"Figure\"})\n",
    "layout_result_1 = model_1.detect(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba8128",
   "metadata": {},
   "source": [
    "Displaying layout_result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1585ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_result_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3a8101",
   "metadata": {},
   "source": [
    "Filtring and displaying layout_result_1 in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a52147",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_result_1 = lp.Layout([b for b in layout_result_1 if b.type in ('Text','Title')])\n",
    "lp.draw_box(img, layout_result_1,  box_width=2, box_alpha=0.2, show_element_type=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d842067a",
   "metadata": {},
   "source": [
    "Detecting layouts by position from resume using First model (Mask R-CNN pre-trained on PrimaLayout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = lp.Detectron2LayoutModel('lp://PrimaLayout/mask_rcnn_R_50_FPN_3x/config',\n",
    "                                 extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.5],\n",
    "                                 label_map={1:\"TextRegion\", 2:\"ImageRegion\", 3:\"TableRegion\", 4:\"MathsRegion\", 5:\"SeparatorRegion\", 6:\"OtherRegion\"})\n",
    "layout_result_2 = model_2.detect(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125ae580",
   "metadata": {},
   "source": [
    "Displaying layout_result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_result_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c03e995",
   "metadata": {},
   "source": [
    "Filtring and displaying layout_result_2 in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a583959",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_result_2 = lp.Layout([b for b in layout_result_2 if b.type == 'TextRegion'])\n",
    "lp.draw_box(img, layout_result_2,  box_width=2, box_alpha=0.2, show_element_type=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc298c2",
   "metadata": {},
   "source": [
    "Converting paddleOCR_result to LayoutParser Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac56735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paddle_layout = lp.elements.layout.Layout()\n",
    "\n",
    "for res in paddleOCR_result:\n",
    "    \n",
    "    box  = res[0]\n",
    "    text = res[1][0]\n",
    "    \n",
    "    x_1 = max(box[0][0], box[3][0])\n",
    "\n",
    "    y_1 = max(box[0][1], box[1][1])\n",
    "\n",
    "    x_2 = max(box[1][0], box[2][0])\n",
    "\n",
    "    y_2 = max(box[2][1], box[3][1])\n",
    "\n",
    "    Rectangle = lp.elements.layout_elements.Rectangle(x_1, y_1, x_2, y_2)\n",
    "\n",
    "    TextBlock = lp.elements.layout_elements.TextBlock(Rectangle)\n",
    "    \n",
    "    TextBlock.text = text\n",
    "\n",
    "    paddle_layout._blocks.append(TextBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638863c7",
   "metadata": {},
   "source": [
    "Displaying paddleOCR_result in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcc7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.draw_box(img, paddle_layout,  box_width=2, box_alpha=0.2, show_element_type=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914acb75",
   "metadata": {},
   "source": [
    "Integrating all results (1st model + 2nd model + paddleOCR) in one layout_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_result = layout_result_1 + layout_result_2 + paddle_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b416f233",
   "metadata": {},
   "source": [
    "Creating a function for consolidating and removing redundant boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56454f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.ops.boxes as bops\n",
    "\n",
    "def set_coordinate(data):\n",
    "\n",
    "  x1 = data.block.x_1\n",
    "  y1 = data.block.y_1\n",
    "  x2 = data.block.x_2\n",
    "  y2 = data.block.y_2\n",
    "\n",
    "  return torch.tensor([[x1, y1, x2, y2]], dtype=torch.float)\n",
    "\n",
    "\n",
    "def check_intersection(block_1, block_2):\n",
    "    \n",
    "    bb1 = set_coordinate(block_1)\n",
    "    bb2 = set_coordinate(block_2)\n",
    "\n",
    "    iou = bops.box_iou(bb1, bb2)\n",
    "\n",
    "    if iou.tolist()[0][0] != 0:\n",
    "        return True\n",
    "    \n",
    "    else :\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def union(layout_result):\n",
    "    \n",
    "    for layout_i in layout_result:\n",
    "        for layout_j in layout_result:\n",
    "            if layout_i == layout_j == layout_result[-1]:\n",
    "                return layout_result\n",
    "            if layout_i != layout_j:\n",
    "                if check_intersection(layout_i, layout_j) == True:\n",
    "                    layout_result.insert(layout_result.index(layout_i),layout_i.union(layout_j,strict=False))\n",
    "                    layout_result.remove(layout_i)\n",
    "                    layout_result.remove(layout_j)\n",
    "                    return union(layout_result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da741012",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_result = union(layout_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f9ea90",
   "metadata": {},
   "source": [
    "Displaying the final in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e333024",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lp.draw_box(img, layout_result,  box_width=2, box_alpha=0.2, show_element_type=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2686093a",
   "metadata": {},
   "source": [
    "#### 2.2.2 Text Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd229f6",
   "metadata": {},
   "source": [
    "After detecting resume's layouts, we need to put them in order before extracting their texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_blocks = lp.Layout([b for b in layout_result])\n",
    "\n",
    "image_width = len(img[0])\n",
    "\n",
    "# Split the resume into 2 column left and right based on x1 coordinate\n",
    "left_blocks  = [b for b in text_blocks if b.block.x_1 <= image_width/4]\n",
    "# Sort element ID of the left column based on y1 coordinate\n",
    "left_blocks.sort(key = lambda b:b.block.y_1)\n",
    "\n",
    "\n",
    "right_blocks = [b for b in text_blocks if b not in left_blocks]\n",
    "# Sort element ID of the right column based on y1 coordinate\n",
    "right_blocks.sort(key = lambda b:b.block.y_1)\n",
    "\n",
    "# Sort the overall element ID starts from left column\n",
    "text_blocks = lp.Layout([b.set(id = idx) for idx, b in enumerate(left_blocks + right_blocks)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ef41d",
   "metadata": {},
   "source": [
    "Calling OCR agent (Tesseract) to extract texts from resume's layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de44fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_agent = lp.TesseractAgent(\"eng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f959d541",
   "metadata": {},
   "source": [
    "Exclude paddleOCR boxes which not affected by layoutParser union due to high quality of the extracted text by PaddleOCR. As a result we keep the original text of PaddleOCR_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in text_blocks:\n",
    "    \n",
    "    # Exclude PaddleOCR_result boxes which their texts already extracted\n",
    "    if block.text == None :\n",
    "\n",
    "        # Crop image around the detected layout\n",
    "        segment_image = (block\n",
    "                           .pad(left=15, right=15, top=5, bottom=5)\n",
    "                           .crop_image(img))\n",
    "\n",
    "        # Perform OCR\n",
    "        text = ocr_agent.detect(segment_image)\n",
    "\n",
    "        # Save OCR result\n",
    "        block.set(text=text, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c26fa26",
   "metadata": {},
   "source": [
    "Saving Layouts's texts in one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb86187",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = [b.text for b in text_blocks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ce684",
   "metadata": {},
   "source": [
    "Cleaning extracted texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb3511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(len(cv)) :\n",
    "    cv[i] = re.sub('\\n', ' ', cv[i])\n",
    "    cv[i] = re.sub('\\x0c', '', cv[i])\n",
    "    cv[i] = re.sub('  ', ' ', cv[i])\n",
    "    cv[i] = re.sub(' \\.', '.', cv[i])\n",
    "    cv[i] = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+:;\\<=>?[]^`{|}~\"\"\"), ' ', cv[i])\n",
    "    cv[i] = cv[i].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b744250",
   "metadata": {},
   "source": [
    "Merging all texts in one text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1baa2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = \"\"\n",
    "for x in cv :\n",
    "    resume = resume + x + \" \"\n",
    "resume=resume[:-1]\n",
    "resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcef97e",
   "metadata": {},
   "source": [
    "Translating resume from french to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "for i in range(len(resume)):\n",
    "    try :\n",
    "        f = translator.detect(resume[i])\n",
    "        if f.lang == 'fr':\n",
    "            t = translator.translate(resume[i], src='fr', dest='en')\n",
    "            resume[i] = t.text\n",
    "            print(resume[i],end='\\n\\n')\n",
    "        elif f.lang == 'en':\n",
    "            t = translator.translate(resume[i], src='fr', dest='en')\n",
    "            resume[i] = t.text\n",
    "            print(resume[i],end='\\n\\n')\n",
    "        else:\n",
    "            print(resume[i])\n",
    "    except : pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b592181",
   "metadata": {},
   "source": [
    "#### 2.2.3 Resume Analysis\n",
    "\n",
    "After extracting the text from the resume and cleaning it up, we will analyze it to find useful informations like skills, personel informations(title, name, location...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b20799",
   "metadata": {},
   "source": [
    "* **<font color=red>Skills Extraction with SkillNer</font>**\n",
    "\n",
    "SkillNer is an NLP module to automatically Extract skills and certifications from unstructured job postings, texts, and applicant's resumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93229c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "# load default skills data base\n",
    "from skillNer.general_params import SKILL_DB\n",
    "\n",
    "# import skill extractor\n",
    "from skillNer.skill_extractor_class import SkillExtractor\n",
    "\n",
    "# init params of skill extractor\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# init skill extractor\n",
    "skill_extractor = SkillExtractor(nlp, SKILL_DB, PhraseMatcher)\n",
    "\n",
    "# extract skills from resume\n",
    "annotations = skill_extractor.annotate(resume)\n",
    "\n",
    "# inspect results by rendering the text with the annotated skills.\n",
    "skill_extractor.describe(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b1f1ab",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Displaying extracted skills with their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8496b77f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skilldic = {}\n",
    "\n",
    "for skill in annotations['results']['full_matches']:\n",
    "    skilldic[SKILL_DB[skill['skill_id']]['skill_name']] = (SKILL_DB[skill['skill_id']]['skill_type'],skill[\"score\"])\n",
    "    \n",
    "for skill in annotations['results']['ngram_scored']:\n",
    "    skilldic[SKILL_DB[skill['skill_id']]['skill_name']] = (SKILL_DB[skill['skill_id']]['skill_type'],skill[\"score\"])\n",
    "    \n",
    "print('Skill',46*\" \" ,\"Type\",10*\" \",\"Score\",\"\\n\")\n",
    "\n",
    "for skill in skilldic :\n",
    "    print(skill, (50-len(skill))*\"-\", \">\" ,skilldic[skill][0], 5*\"-\",skilldic[skill][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f9a42a",
   "metadata": {},
   "source": [
    "* **<font color=red>Named-entity recognition (NER)</font>**\n",
    "\n",
    "Named-entity recognition (NER) is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cc63c1",
   "metadata": {},
   "source": [
    "* **<font color=green>NER with SpaCy </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452c6aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(resume)\n",
    "\n",
    "for ent in doc.ents :\n",
    "    print(ent.text,(50-len(ent.text)) * '-',  \">\"  ,ent.label_,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda1b331",
   "metadata": {},
   "source": [
    "* **<font color=green>NER with Stanza </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53709989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "from stanza.server import CoreNLPClient\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "with CoreNLPClient(\n",
    "        \n",
    "        annotators = ['tokenize','ssplit','pos','lemma','ner'],\n",
    "        timeout    = 30000,\n",
    "        memory     = '10G',\n",
    "        threads    = '4',\n",
    "        be_quiet   = True\n",
    "\n",
    "                            ) as client :\n",
    "    \n",
    "    ann = client.annotate(resume,output_format='json')\n",
    "\n",
    "for sen in ann['sentences']:\n",
    "    for ent in sen['entitymentions']:\n",
    "        print(ent['text'],(50-len(ent['text']))*\"-\", \">\" ,ent['ner'],\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
